{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45ee4fd3-322d-4806-bfd2-446762009e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# Phase 3: Data Preprocessing\n",
    "# -----------------------------------------------------------------------------------\n",
    "# Objective:\n",
    "# Prepare the synthetic financial transaction dataset for machine learning by\n",
    "# cleaning, transforming, and encoding the data.\n",
    "\n",
    "# Key Steps:\n",
    "# 1. Handle missing values (if any).\n",
    "# 2. Convert categorical columns (e.g., vendor, category, payment method) into\n",
    "#    numerical representations suitable for ML models.\n",
    "# 3. Parse and extract features from dates (e.g., day of week, month).\n",
    "# 4. Normalize or scale the transaction amount column.\n",
    "# 5. Finalize the feature set (X) and target labels (y).\n",
    "\n",
    "# Output:\n",
    "# A clean and ready-to-use dataset for training and evaluation in Phase 4.\n",
    "\n",
    "# Note:\n",
    "# This notebook assumes you already ran `01_generate_data.ipynb` and\n",
    "# `02_data_exploration.ipynb`, and have the dataset saved as `data/synthetic_finory_transactions.csv`.\n",
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d66644b-db85-44b1-92fe-4e93e4b68cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>vendor</th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e541e1ae-893d-4479-a25d-326c8f7b559e</td>\n",
       "      <td>NortonLifeLock</td>\n",
       "      <td>18.77</td>\n",
       "      <td>SecuritySystem</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Story do here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23b8a680-a487-4131-ba03-3a191faf5232</td>\n",
       "      <td>Republic Services</td>\n",
       "      <td>120.40</td>\n",
       "      <td>Trash</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>Black board dark toward data economic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70dc4c45-ede7-4a89-afae-cb1949fe8992</td>\n",
       "      <td>Consolidated Edison</td>\n",
       "      <td>52.67</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Act peace stock whether.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c80e262-f04e-41e4-a138-ff16bb52efdd</td>\n",
       "      <td>Paychex</td>\n",
       "      <td>36.52</td>\n",
       "      <td>Payroll</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Cost receive contain hit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c48818-534c-41f7-a229-b4386cafac1a</td>\n",
       "      <td>Molson Coors Beverage Company</td>\n",
       "      <td>6.78</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Unit magazine ten.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         transaction_id                         vendor  \\\n",
       "0  e541e1ae-893d-4479-a25d-326c8f7b559e                 NortonLifeLock   \n",
       "1  23b8a680-a487-4131-ba03-3a191faf5232              Republic Services   \n",
       "2  70dc4c45-ede7-4a89-afae-cb1949fe8992            Consolidated Edison   \n",
       "3  1c80e262-f04e-41e4-a138-ff16bb52efdd                        Paychex   \n",
       "4  00c48818-534c-41f7-a229-b4386cafac1a  Molson Coors Beverage Company   \n",
       "\n",
       "   amount        category        date payment_method  \\\n",
       "0   18.77  SecuritySystem  2025-06-12           Visa   \n",
       "1  120.40           Trash  2025-05-01     MasterCard   \n",
       "2   52.67       Utilities  2025-06-05           Visa   \n",
       "3   36.52         Payroll  2025-02-21           Visa   \n",
       "4    6.78         Alcohol  2025-03-24           Visa   \n",
       "\n",
       "                                     note  \n",
       "0                          Story do here.  \n",
       "1  Black board dark toward data economic.  \n",
       "2                Act peace stock whether.  \n",
       "3               Cost receive contain hit.  \n",
       "4                      Unit magazine ten.  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the synthetic Finory transaction dataset (5,000 rows) for preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/synthetic_finory_transactions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd97e0c5-6bff-4dfc-ba49-832aad155136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vendor grouping applied. Sample:\n",
      "                          vendor         vendor_group\n",
      "0                 NortonLifeLock           Technology\n",
      "1              Republic Services   Energy & Utilities\n",
      "2            Consolidated Edison   Energy & Utilities\n",
      "3                        Paychex  Finance & Insurance\n",
      "4  Molson Coors Beverage Company               Retail\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# Vendor Grouping: Reduce 330+ vendors into broader categories for better model generalization\n",
    "# -----------------------------------------------------------------------------------\n",
    "from vendor_mapping import vendor_groups  # Import the mapping from your vendor_mapping.py\n",
    "\n",
    "# Map each vendor into a broader group (e.g., Amazon → Retail)\n",
    "df['vendor_group'] = df['vendor'].map(vendor_groups)\n",
    "\n",
    "# Fallback to 'Other' for vendors not in the mapping\n",
    "df['vendor_group'] = df['vendor_group'].fillna('Other')\n",
    "\n",
    "print(\"✅ Vendor grouping applied. Sample:\")\n",
    "print(df[['vendor', 'vendor_group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ad2e38d-0ace-418c-bdfc-991e6492f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category merging applied. Sample:\n",
      "         category  category_merged\n",
      "0  SecuritySystem            Other\n",
      "1           Trash            Other\n",
      "2       Utilities  Housing & Bills\n",
      "3         Payroll            Other\n",
      "4         Alcohol    Food & Dining\n"
     ]
    }
   ],
   "source": [
    "# ✅ Merge detailed categories into ~10 broader groups for better model performance\n",
    "category_merge_map = {\n",
    "    'Groceries': 'Food & Dining',\n",
    "    'Alcohol': 'Food & Dining',\n",
    "    'DiningOut': 'Food & Dining',\n",
    "    \n",
    "    'Electronics': 'Shopping & Electronics',\n",
    "    'Software': 'Shopping & Electronics',\n",
    "    'Hardware': 'Shopping & Electronics',\n",
    "    \n",
    "    'Gas': 'Transport & Travel',\n",
    "    'Transportation': 'Transport & Travel',\n",
    "    'Travel': 'Transport & Travel',\n",
    "    \n",
    "    'Rent': 'Housing & Bills',\n",
    "    'Utilities': 'Housing & Bills',\n",
    "    'Insurance': 'Housing & Bills',\n",
    "    \n",
    "    'Entertainment': 'Entertainment',\n",
    "    'Subscriptions': 'Entertainment',\n",
    "    'Games': 'Entertainment',\n",
    "    \n",
    "    'BankFees': 'Financial Services',\n",
    "    'Interest': 'Financial Services',\n",
    "    'LoanPayments': 'Financial Services',\n",
    "    \n",
    "    'Healthcare': 'Healthcare',\n",
    "    'Pharmacy': 'Healthcare',\n",
    "    'Medical': 'Healthcare',\n",
    "    \n",
    "    'Education': 'Education',\n",
    "    'Books': 'Education',\n",
    "    'OnlineCourses': 'Education',\n",
    "    \n",
    "    'Charity': 'Gifts & Charity',\n",
    "    'Donations': 'Gifts & Charity',\n",
    "    'Gifts': 'Gifts & Charity',\n",
    "    \n",
    "    'Other': 'Other'\n",
    "}\n",
    "\n",
    "# Apply category merging\n",
    "df['category_merged'] = df['category'].map(category_merge_map).fillna('Other')\n",
    "\n",
    "print(\"✅ Category merging applied. Sample:\")\n",
    "print(df[['category', 'category_merged']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1b60207-8bb2-411f-ba92-1a7633f73040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id     0\n",
       "vendor             0\n",
       "amount             0\n",
       "category           0\n",
       "date               0\n",
       "payment_method     0\n",
       "note               0\n",
       "vendor_group       0\n",
       "category_merged    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing/null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6eb2cab3-2fa1-4cdb-b01f-d43cc274a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   transaction_id   5000 non-null   object \n",
      " 1   vendor           5000 non-null   object \n",
      " 2   amount           5000 non-null   float64\n",
      " 3   category         5000 non-null   object \n",
      " 4   date             5000 non-null   object \n",
      " 5   payment_method   5000 non-null   object \n",
      " 6   note             5000 non-null   object \n",
      " 7   vendor_group     5000 non-null   object \n",
      " 8   category_merged  5000 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# View data types and non-null counts; ensure 'date' column is in datetime format\n",
    "df.info()\n",
    "\n",
    "# If needed, convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a5f3eac-cd3c-4d6d-8ab9-bafdc213cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of week, month, and log-transformed amount for feature engineering\n",
    "df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday\n",
    "df['month'] = df['date'].dt.month\n",
    "df['amount_log'] = np.log1p(df['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c10b650a-427c-42fc-96a9-deba3fea6c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vendor group, payment method, and merged category encoded successfully!\n",
      "          vendor_group  vendor_encoded payment_method  payment_encoded  \\\n",
      "0           Technology               9           Visa                4   \n",
      "1   Energy & Utilities               0     MasterCard                2   \n",
      "2   Energy & Utilities               0           Visa                4   \n",
      "3  Finance & Insurance               2           Visa                4   \n",
      "4               Retail               8           Visa                4   \n",
      "\n",
      "   category_merged  category_encoded  \n",
      "0            Other                 5  \n",
      "1            Other                 5  \n",
      "2  Housing & Bills                 4  \n",
      "3            Other                 5  \n",
      "4    Food & Dining                 2  \n"
     ]
    }
   ],
   "source": [
    "# ✅ Encode grouped vendor, payment method, and merged category as numerical labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize label encoders\n",
    "le_vendor = LabelEncoder()\n",
    "le_payment = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "\n",
    "# Encode the grouped vendor column (not the original vendor name)\n",
    "df['vendor_encoded'] = le_vendor.fit_transform(df['vendor_group'])\n",
    "\n",
    "# Encode payment method\n",
    "df['payment_encoded'] = le_payment.fit_transform(df['payment_method'])\n",
    "\n",
    "# ✅ Encode the merged category column (category_merged, not the original category)\n",
    "df['category_encoded'] = le_category.fit_transform(df['category_merged'])\n",
    "\n",
    "print(\"✅ Vendor group, payment method, and merged category encoded successfully!\")\n",
    "print(df[['vendor_group', 'vendor_encoded', 'payment_method', 'payment_encoded', \n",
    "          'category_merged', 'category_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19f05080-60bc-4853-9b9a-8b6e95e714a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data split into training and test sets!\n",
      "Training set size: 4000 samples\n",
      "Test set size: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define feature columns (X) and target (y)\n",
    "X = df[['vendor_encoded', 'amount_log', 'payment_encoded', 'day_of_week', 'month']]\n",
    "y = df['category_encoded']\n",
    "\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Data split into training and test sets!\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5da4dc7d-e118-4c69-b160-d95fa3ebfff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessed dataset saved as synthetic_finory_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ Save the fully preprocessed dataset for later model training\n",
    "df.to_csv(\"../data/synthetic_finory_preprocessed.csv\", index=False)\n",
    "print(\"✅ Preprocessed dataset saved as synthetic_finory_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "36b8b3ae-fb69-46b9-b820-946d1a692054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# Phase 3: Data Preprocessing\n",
    "# -----------------------------------------------------------------------------------\n",
    "# Objective:\n",
    "# Prepare the synthetic transaction data for machine learning by engineering\n",
    "# useful features, handling categorical variables, and splitting into training\n",
    "# and testing sets.\n",
    "#\n",
    "# Key Steps:\n",
    "# - Checked for missing values\n",
    "# - Parsed and extracted date-related features (day of week, month)\n",
    "# - Log-transformed skewed 'amount' field\n",
    "# - Encoded categorical variables (vendor, payment method, category)\n",
    "# - Split dataset into train/test sets for modeling\n",
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a3d91ba-38b9-4fbf-941f-e6d79e4f34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label encoders saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save label encoders after preprocessing\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "label_encoders = {\n",
    "    \"vendor_encoder\": le_vendor,\n",
    "    \"payment_encoder\": le_payment,\n",
    "    \"category_encoder\": le_category\n",
    "}\n",
    "\n",
    "joblib.dump(label_encoders, \"../models/finory_label_encoders.joblib\")\n",
    "print(\"✅ Label encoders saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e1738-74c9-4478-92ae-ce7ccf519a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
